{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd3c4eb-78ad-4e86-b531-d0b224e2d782",
   "metadata": {},
   "source": [
    "# Travel Personality Classification Project\n",
    "\n",
    "## Overview\n",
    "This project aims to build a machine learning model that can classify users into different travel personality types, such as **Adventure Seeker**, **Cultural Explorer**, **Luxury Traveler**, and **Nature Lover**. The classification is based on user preferences and demographic information, helping us understand and categorize users’ travel inclinations. To demonstrate proficiency in popular machine learning frameworks, the project is implemented using both **TensorFlow** and **PyTorch**.\n",
    "\n",
    "## Objectives\n",
    "The primary goals of this project are:\n",
    "1. To create an accurate travel personality classification model.\n",
    "2. To showcase implementations using **TensorFlow** and **PyTorch** for comparison.\n",
    "3. To highlight the strengths of each framework in handling multi-class classification tasks.\n",
    "\n",
    "## Dataset\n",
    "The dataset consists of synthetic records representing user demographics and travel preferences, such as:\n",
    "- **Age**\n",
    "- **Location** (encoded as categorical variables)\n",
    "- **Budget Preference**\n",
    "- **Adventure Score**\n",
    "- **Luxury Score**\n",
    "- **Cultural Interest**\n",
    "- **Nature Lover Score**\n",
    "\n",
    "The target variable is the **Travel Personality** type, with four distinct classes.\n",
    "\n",
    "## Data Preprocessing\n",
    "The following preprocessing steps are applied:\n",
    "1. **Label Encoding**: Converting categorical labels (travel personalities) into integer classes.\n",
    "2. **Feature Scaling**: Standardizing features to have consistent influence on the model.\n",
    "3. **One-Hot Encoding** (for TensorFlow): Converting target labels into a one-hot encoded format to support multi-class classification.\n",
    "\n",
    "## Model Architectures\n",
    "\n",
    "### TensorFlow Model\n",
    "The TensorFlow model is a feed-forward neural network configured with three hidden layers using ReLU activation, followed by a Softmax output layer. This model is optimized using the Adam optimizer and utilizes Categorical Crossentropy as the loss function, making it suitable for multi-class classification.\n",
    "\n",
    "### PyTorch Model\n",
    "The PyTorch model uses a similar architecture, implemented as a custom neural network class with four fully connected layers. The hidden layers apply ReLU activation, and the output layer uses Softmax. The Adam optimizer and CrossEntropyLoss are used for optimization and loss calculation, respectively, which are compatible with multi-class classification in PyTorch.\n",
    "\n",
    "## Training and Evaluation\n",
    "Both models are trained and validated using cross-validation to ensure model generalization. Evaluation on a test dataset assesses performance, with key metrics including **accuracy** and **loss**. Cross-validation provides insight into each model’s ability to generalize, while test accuracy reveals the model’s real-world performance.\n",
    "\n",
    "## Results and Observations\n",
    "Both the TensorFlow and PyTorch models achieved high classification accuracy, confirming the effectiveness of the model architectures. Future enhancements could include:\n",
    "- **Hyperparameter Tuning**: Experimenting with batch sizes, learning rates, and additional layers.\n",
    "- **Data Augmentation**: Expanding the dataset to improve model robustness and generalization.\n",
    "\n",
    "## Conclusion\n",
    "This project demonstrates the process of building and evaluating a multi-class classification model using both TensorFlow and PyTorch. The successful classification accuracy achieved highlights the capabilities of each framework in handling neural network-based classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0d1214-4178-44cf-b10b-4c88edd80772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('your_travel_data.csv')\n",
    "\n",
    "# One-hot encode the 'location' column to convert it to numeric format\n",
    "data = pd.get_dummies(data, columns=['location'], drop_first=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=['travel_personality'])\n",
    "y = data['travel_personality']\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)  # Convert to integer classes\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a9038-d80b-4344-9925-6499d9d5b42b",
   "metadata": {},
   "source": [
    "Step 2: Import TensorFlow and Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a5461c-f0f6-405c-b067-f84ba3054672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert y_train and y_test to categorical format\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# Define the model architecture using an Input layer\n",
    "model_tf = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Define the input shape here\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(y_train_categorical.shape[1], activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b701a-de60-423b-ac0e-a4828e59a9a7",
   "metadata": {},
   "source": [
    "Step 3: Compile the TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492ad453-c86b-4bb3-82f4-e8ddd63ab6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical crossentropy for multi-class classification\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878fdd5-1678-43d9-b591-bf8854452d88",
   "metadata": {},
   "source": [
    "Step 4: Train the TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377e094a-48a5-4637-b9c3-adec87c29242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3886 - loss: 1.3138 - val_accuracy: 0.5350 - val_loss: 1.0662\n",
      "Epoch 2/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5875 - loss: 1.0053 - val_accuracy: 0.6850 - val_loss: 0.7888\n",
      "Epoch 3/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.6492 - val_accuracy: 0.7650 - val_loss: 0.5870\n",
      "Epoch 4/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.4340 - val_accuracy: 0.7900 - val_loss: 0.4733\n",
      "Epoch 5/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3320 - val_accuracy: 0.8100 - val_loss: 0.4239\n",
      "Epoch 6/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2732 - val_accuracy: 0.8450 - val_loss: 0.3941\n",
      "Epoch 7/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.2414 - val_accuracy: 0.8650 - val_loss: 0.3414\n",
      "Epoch 8/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2259 - val_accuracy: 0.8900 - val_loss: 0.3087\n",
      "Epoch 9/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1573 - val_accuracy: 0.9050 - val_loss: 0.2688\n",
      "Epoch 10/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.1333 - val_accuracy: 0.9200 - val_loss: 0.2395\n",
      "Epoch 11/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.1179 - val_accuracy: 0.9250 - val_loss: 0.2220\n",
      "Epoch 12/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0832 - val_accuracy: 0.9300 - val_loss: 0.1994\n",
      "Epoch 13/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0763 - val_accuracy: 0.9450 - val_loss: 0.1783\n",
      "Epoch 14/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0559 - val_accuracy: 0.9450 - val_loss: 0.1779\n",
      "Epoch 15/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0522 - val_accuracy: 0.9550 - val_loss: 0.1509\n",
      "Epoch 16/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0462 - val_accuracy: 0.9600 - val_loss: 0.1459\n",
      "Epoch 17/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0367 - val_accuracy: 0.9650 - val_loss: 0.1365\n",
      "Epoch 18/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0353 - val_accuracy: 0.9650 - val_loss: 0.1387\n",
      "Epoch 19/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0386 - val_accuracy: 0.9650 - val_loss: 0.1242\n",
      "Epoch 20/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0229 - val_accuracy: 0.9650 - val_loss: 0.1178\n",
      "Epoch 21/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0235 - val_accuracy: 0.9700 - val_loss: 0.1115\n",
      "Epoch 22/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0170 - val_accuracy: 0.9600 - val_loss: 0.1143\n",
      "Epoch 23/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9650 - val_loss: 0.1171\n",
      "Epoch 24/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0139 - val_accuracy: 0.9650 - val_loss: 0.1154\n",
      "Epoch 25/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0112 - val_accuracy: 0.9700 - val_loss: 0.1043\n",
      "Epoch 26/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9700 - val_loss: 0.1084\n",
      "Epoch 27/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9700 - val_loss: 0.1005\n",
      "Epoch 28/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9700 - val_loss: 0.1038\n",
      "Epoch 29/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9700 - val_loss: 0.0977\n",
      "Epoch 30/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9750 - val_loss: 0.0968\n",
      "Epoch 31/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9700 - val_loss: 0.0941\n",
      "Epoch 32/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9750 - val_loss: 0.0935\n",
      "Epoch 33/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9800 - val_loss: 0.0979\n",
      "Epoch 34/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9750 - val_loss: 0.0955\n",
      "Epoch 35/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9750 - val_loss: 0.0889\n",
      "Epoch 36/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9750 - val_loss: 0.0895\n",
      "Epoch 37/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9750 - val_loss: 0.0894\n",
      "Epoch 38/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9750 - val_loss: 0.0865\n",
      "Epoch 39/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9800 - val_loss: 0.0893\n",
      "Epoch 40/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9750 - val_loss: 0.0881\n",
      "Epoch 41/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9750 - val_loss: 0.0867\n",
      "Epoch 42/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9750 - val_loss: 0.0872\n",
      "Epoch 43/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9800 - val_loss: 0.0866\n",
      "Epoch 44/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9800 - val_loss: 0.0831\n",
      "Epoch 45/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9750 - val_loss: 0.0868\n",
      "Epoch 46/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9800 - val_loss: 0.0819\n",
      "Epoch 47/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9800 - val_loss: 0.0826\n",
      "Epoch 48/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9850 - val_loss: 0.0821\n",
      "Epoch 49/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9800 - val_loss: 0.0824\n",
      "Epoch 50/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9800 - val_loss: 0.0818\n",
      "Epoch 51/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9850 - val_loss: 0.0817\n",
      "Epoch 52/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2066e-04 - val_accuracy: 0.9850 - val_loss: 0.0803\n",
      "Epoch 53/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6068e-04 - val_accuracy: 0.9850 - val_loss: 0.0821\n",
      "Epoch 54/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2808e-04 - val_accuracy: 0.9800 - val_loss: 0.0807\n",
      "Epoch 55/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2006e-04 - val_accuracy: 0.9800 - val_loss: 0.0803\n",
      "Epoch 56/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5051e-04 - val_accuracy: 0.9850 - val_loss: 0.0795\n",
      "Epoch 57/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6019e-04 - val_accuracy: 0.9800 - val_loss: 0.0812\n",
      "Epoch 58/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1558e-04 - val_accuracy: 0.9800 - val_loss: 0.0797\n",
      "Epoch 59/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8920e-04 - val_accuracy: 0.9800 - val_loss: 0.0802\n",
      "Epoch 60/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1661e-04 - val_accuracy: 0.9850 - val_loss: 0.0791\n",
      "Epoch 61/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2878e-04 - val_accuracy: 0.9800 - val_loss: 0.0787\n",
      "Epoch 62/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3011e-04 - val_accuracy: 0.9850 - val_loss: 0.0805\n",
      "Epoch 63/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7565e-04 - val_accuracy: 0.9800 - val_loss: 0.0786\n",
      "Epoch 64/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3541e-04 - val_accuracy: 0.9850 - val_loss: 0.0796\n",
      "Epoch 65/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0655e-04 - val_accuracy: 0.9850 - val_loss: 0.0795\n",
      "Epoch 66/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7980e-04 - val_accuracy: 0.9800 - val_loss: 0.0803\n",
      "Epoch 67/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5231e-04 - val_accuracy: 0.9800 - val_loss: 0.0784\n",
      "Epoch 68/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8107e-04 - val_accuracy: 0.9800 - val_loss: 0.0790\n",
      "Epoch 69/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0198e-04 - val_accuracy: 0.9800 - val_loss: 0.0801\n",
      "Epoch 70/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1754e-04 - val_accuracy: 0.9800 - val_loss: 0.0780\n",
      "Epoch 71/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5852e-04 - val_accuracy: 0.9800 - val_loss: 0.0783\n",
      "Epoch 72/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0736e-04 - val_accuracy: 0.9800 - val_loss: 0.0785\n",
      "Epoch 73/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8798e-04 - val_accuracy: 0.9800 - val_loss: 0.0794\n",
      "Epoch 74/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6099e-04 - val_accuracy: 0.9800 - val_loss: 0.0782\n",
      "Epoch 75/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0960e-04 - val_accuracy: 0.9800 - val_loss: 0.0791\n",
      "Epoch 76/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2890e-04 - val_accuracy: 0.9800 - val_loss: 0.0784\n",
      "Epoch 77/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7929e-04 - val_accuracy: 0.9800 - val_loss: 0.0786\n",
      "Epoch 78/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7159e-04 - val_accuracy: 0.9800 - val_loss: 0.0783\n",
      "Epoch 79/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6638e-04 - val_accuracy: 0.9800 - val_loss: 0.0775\n",
      "Epoch 80/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3821e-04 - val_accuracy: 0.9800 - val_loss: 0.0790\n",
      "Epoch 81/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6533e-04 - val_accuracy: 0.9800 - val_loss: 0.0784\n",
      "Epoch 82/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3490e-04 - val_accuracy: 0.9800 - val_loss: 0.0781\n",
      "Epoch 83/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5710e-04 - val_accuracy: 0.9800 - val_loss: 0.0790\n",
      "Epoch 84/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1292e-04 - val_accuracy: 0.9800 - val_loss: 0.0792\n",
      "Epoch 85/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3781e-04 - val_accuracy: 0.9800 - val_loss: 0.0781\n",
      "Epoch 86/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9819e-04 - val_accuracy: 0.9800 - val_loss: 0.0795\n",
      "Epoch 87/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8517e-04 - val_accuracy: 0.9800 - val_loss: 0.0781\n",
      "Epoch 88/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8846e-04 - val_accuracy: 0.9800 - val_loss: 0.0777\n",
      "Epoch 89/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9962e-04 - val_accuracy: 0.9800 - val_loss: 0.0790\n",
      "Epoch 90/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9106e-04 - val_accuracy: 0.9800 - val_loss: 0.0791\n",
      "Epoch 91/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7634e-04 - val_accuracy: 0.9800 - val_loss: 0.0795\n",
      "Epoch 92/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8820e-04 - val_accuracy: 0.9800 - val_loss: 0.0788\n",
      "Epoch 93/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6044e-04 - val_accuracy: 0.9800 - val_loss: 0.0796\n",
      "Epoch 94/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4751e-04 - val_accuracy: 0.9800 - val_loss: 0.0795\n",
      "Epoch 95/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4534e-04 - val_accuracy: 0.9800 - val_loss: 0.0795\n",
      "Epoch 96/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2665e-04 - val_accuracy: 0.9800 - val_loss: 0.0799\n",
      "Epoch 97/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2690e-04 - val_accuracy: 0.9800 - val_loss: 0.0792\n",
      "Epoch 98/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4075e-04 - val_accuracy: 0.9800 - val_loss: 0.0801\n",
      "Epoch 99/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2663e-04 - val_accuracy: 0.9800 - val_loss: 0.0790\n",
      "Epoch 100/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1834e-04 - val_accuracy: 0.9800 - val_loss: 0.0802\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_tf = model_tf.fit(X_train, y_train_categorical, epochs=100, batch_size=16, validation_data=(X_test, y_test_categorical))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7b87c-d2fa-40ad-9a45-28dc33b88b11",
   "metadata": {},
   "source": [
    "Step 5: Evaluate the TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71f89be1-6879-48b2-a36e-825441b40783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.1122\n",
      "TensorFlow Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model_tf.evaluate(X_test, y_test_categorical)\n",
    "print(f\"TensorFlow Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd17fa1f-be25-4171-915a-bce6f9352bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.2.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/203.0 MB 3.4 MB/s eta 0:01:01\n",
      "   ---------------------------------------- 1.6/203.0 MB 4.0 MB/s eta 0:00:51\n",
      "    --------------------------------------- 2.6/203.0 MB 4.4 MB/s eta 0:00:46\n",
      "    --------------------------------------- 4.2/203.0 MB 5.3 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 5.8/203.0 MB 5.9 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 7.6/203.0 MB 6.3 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 10.0/203.0 MB 7.0 MB/s eta 0:00:28\n",
      "   -- ------------------------------------- 12.1/203.0 MB 7.5 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 14.4/203.0 MB 7.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 17.0/203.0 MB 8.5 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 19.7/203.0 MB 8.8 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 22.3/203.0 MB 9.2 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 24.9/203.0 MB 9.4 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 27.8/203.0 MB 9.8 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 30.9/203.0 MB 10.2 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 33.3/203.0 MB 10.3 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 36.7/203.0 MB 10.6 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 40.1/203.0 MB 10.9 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 43.0/203.0 MB 11.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 46.9/203.0 MB 11.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 50.6/203.0 MB 11.8 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 53.7/203.0 MB 12.0 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 57.4/203.0 MB 12.2 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 61.3/203.0 MB 12.5 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 65.0/203.0 MB 12.7 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 68.2/203.0 MB 12.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 72.1/203.0 MB 13.1 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 76.0/203.0 MB 13.3 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 79.7/203.0 MB 13.4 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 83.6/203.0 MB 13.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 87.8/203.0 MB 13.8 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 92.0/203.0 MB 14.0 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 96.5/203.0 MB 14.3 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 100.7/203.0 MB 14.4 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 104.9/203.0 MB 14.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 109.1/203.0 MB 14.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 113.0/203.0 MB 14.9 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 116.9/203.0 MB 15.0 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 121.6/203.0 MB 15.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 125.3/203.0 MB 15.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 128.7/203.0 MB 15.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.9/203.0 MB 15.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 136.8/203.0 MB 15.5 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 141.6/203.0 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 145.5/203.0 MB 15.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.2/203.0 MB 15.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 153.6/203.0 MB 15.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 158.1/203.0 MB 16.0 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 162.5/203.0 MB 16.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 167.2/203.0 MB 16.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 172.0/203.0 MB 16.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.9/203.0 MB 16.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.6/203.0 MB 16.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.5/203.0 MB 16.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 189.3/203.0 MB 16.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.7/203.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.7/203.0 MB 16.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.4/203.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 20.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 20.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55060b1d-9c8e-41ff-acc8-dfa0169394ff",
   "metadata": {},
   "source": [
    "Step 2: Import PyTorch and Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57dbbb3e-501e-43b0-b5e3-1fa0ba26a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Define DataLoader for training\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the model architecture in PyTorch\n",
    "class TravelPersonalityNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(TravelPersonalityNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model_pt = TravelPersonalityNN(X_train.shape[1], len(set(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb3167-3e19-441c-982d-41040a75e654",
   "metadata": {},
   "source": [
    "Step 3: Define the Loss Function and Optimizer in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3c87a60-df78-497c-850b-26f8382484d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_pt.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222bcfb7-f926-459e-8f96-eb51f9ccae97",
   "metadata": {},
   "source": [
    "Step 4: Train the PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd80302-053c-4729-b236-29ea81c6aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model_pt(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Update weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2e81d-1648-4acb-a4fc-ea9af41b22b2",
   "metadata": {},
   "source": [
    "Step 5: Evaluate the PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e03799e-8274-4e4b-8959-5ae24a1e5ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "with torch.no_grad():\n",
    "    outputs = model_pt(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    test_accuracy = (predicted == y_test_tensor).float().mean().item()\n",
    "    print(f\"PyTorch Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983b415-73f4-4e5d-8eab-0317cfc642f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
